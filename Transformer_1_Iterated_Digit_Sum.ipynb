{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.optim as optim"
      ],
      "metadata": {
        "id": "J5kf8Df8nOsg"
      },
      "execution_count": 1,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")"
      ],
      "metadata": {
        "id": "WGpFk45rnRMR"
      },
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def iterated_digit_sum(n):\n",
        "    while n > 9:\n",
        "        n = sum(int(digit) for digit in str(n))\n",
        "    return n"
      ],
      "metadata": {
        "id": "MXbMGsfPnSS0"
      },
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def number_to_digits(n, max_digits=9):\n",
        "    digits = [int(d) for d in str(n)]\n",
        "    return [0] * (max_digits - len(digits)) + digits"
      ],
      "metadata": {
        "id": "rL0hSk-2nTmA"
      },
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "num_samples = 20000\n",
        "X = np.random.randint(0, 100_000_000, size=num_samples)\n",
        "y = np.array([iterated_digit_sum(x) for x in X])\n",
        "X = np.array([number_to_digits(x) for x in X])\n",
        "\n",
        "# Splitting data\n",
        "split = int(0.8 * num_samples)\n",
        "X_train, X_val = X[:split], X[split:]\n",
        "y_train, y_val = y[:split], y[split:]"
      ],
      "metadata": {
        "id": "-7YyDil2nUVj"
      },
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "class SimpleTransformer(nn.Module):\n",
        "    def __init__(self, d_model, nhead, num_layers):\n",
        "        super(SimpleTransformer, self).__init__()\n",
        "        self.embedding = nn.Embedding(10, d_model)\n",
        "        self.transformer = nn.Transformer(d_model, nhead, num_layers, num_layers)\n",
        "        self.fc = nn.Linear(d_model, 10)\n",
        "\n",
        "    def forward(self, src):\n",
        "        src = self.embedding(src)\n",
        "        src = src.permute(1, 0, 2)\n",
        "        output = self.transformer(src, src)\n",
        "        return self.fc(output[-1])\n",
        "\n",
        "\n",
        "d_model = 64\n",
        "nhead = 8\n",
        "num_layers = 1\n",
        "\n",
        "net = SimpleTransformer(d_model, nhead, num_layers).to(device)\n",
        "criterion = nn.CrossEntropyLoss()\n",
        "optimizer = optim.Adam(net.parameters(), lr=0.0005)\n"
      ],
      "metadata": {
        "id": "vhgKSlZHnbyf"
      },
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Initialize weights using Xavier (Glorot) initialization\n",
        "def initialize_weights(m):\n",
        "    if isinstance(m, nn.Linear):\n",
        "        nn.init.xavier_uniform_(m.weight)\n",
        "        if m.bias is not None:\n",
        "            nn.init.constant_(m.bias, 0)\n",
        "\n",
        "net.apply(initialize_weights)"
      ],
      "metadata": {
        "id": "a0r8zIaNnemo"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ItyvTgqJnL22",
        "outputId": "525a47da-293a-4a45-9aed-231f2bda918b"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/3500 - Loss: 3.043935537338257 - Val Loss: 2.700690507888794\n",
            "Epoch 101/3500 - Loss: 2.2009785175323486 - Val Loss: 2.2028584480285645\n",
            "Epoch 201/3500 - Loss: 2.171909809112549 - Val Loss: 2.2190098762512207\n",
            "Epoch 301/3500 - Loss: 2.11291766166687 - Val Loss: 2.2495791912078857\n",
            "Epoch 401/3500 - Loss: 2.0000765323638916 - Val Loss: 2.323840618133545\n",
            "Epoch 501/3500 - Loss: 1.8489491939544678 - Val Loss: 2.4132754802703857\n",
            "Epoch 601/3500 - Loss: 1.667099952697754 - Val Loss: 2.3689167499542236\n",
            "Epoch 701/3500 - Loss: 0.9895638227462769 - Val Loss: 1.0590077638626099\n",
            "Epoch 801/3500 - Loss: 0.19639430940151215 - Val Loss: 0.07977096736431122\n",
            "Epoch 901/3500 - Loss: 0.07481522113084793 - Val Loss: 0.025816738605499268\n",
            "Epoch 1001/3500 - Loss: 0.04443313553929329 - Val Loss: 0.00972510501742363\n",
            "Epoch 1101/3500 - Loss: 0.030537474900484085 - Val Loss: 0.00576006667688489\n",
            "Epoch 1201/3500 - Loss: 0.020608684048056602 - Val Loss: 0.00345575506798923\n",
            "Epoch 1301/3500 - Loss: 0.016974303871393204 - Val Loss: 0.002486505778506398\n",
            "Epoch 1401/3500 - Loss: 0.01641891337931156 - Val Loss: 0.002258535474538803\n",
            "Epoch 1501/3500 - Loss: 0.0126614635810256 - Val Loss: 0.001952801481820643\n",
            "Epoch 1601/3500 - Loss: 0.010194042697548866 - Val Loss: 0.0020768502727150917\n",
            "Epoch 1701/3500 - Loss: 0.00931788980960846 - Val Loss: 0.0014371908036991954\n",
            "Epoch 1801/3500 - Loss: 0.008049311116337776 - Val Loss: 0.0017792514991015196\n",
            "Epoch 1901/3500 - Loss: 0.008056492544710636 - Val Loss: 0.0016847040969878435\n",
            "Epoch 2001/3500 - Loss: 0.005336580332368612 - Val Loss: 0.0009368087048642337\n",
            "Epoch 2101/3500 - Loss: 0.005765012931078672 - Val Loss: 0.001477345242165029\n",
            "Epoch 2201/3500 - Loss: 0.006688596215099096 - Val Loss: 0.0008692028350196779\n",
            "Epoch 2301/3500 - Loss: 0.005893859080970287 - Val Loss: 0.0010291922371834517\n",
            "Epoch 2401/3500 - Loss: 0.005579360295087099 - Val Loss: 0.000703387544490397\n",
            "Epoch 2501/3500 - Loss: 0.004563404247164726 - Val Loss: 0.0009315152419731021\n",
            "Epoch 2601/3500 - Loss: 0.0064009097404778 - Val Loss: 0.0010072599397972226\n",
            "Epoch 2701/3500 - Loss: 0.004549623467028141 - Val Loss: 0.000809611810836941\n",
            "Epoch 2801/3500 - Loss: 0.004853455815464258 - Val Loss: 0.0016438682796433568\n",
            "Epoch 2901/3500 - Loss: 0.004277314990758896 - Val Loss: 0.001039830967783928\n",
            "Epoch 3001/3500 - Loss: 0.0035004131495952606 - Val Loss: 0.001289714709855616\n",
            "Epoch 3101/3500 - Loss: 0.002814008155837655 - Val Loss: 0.0006565139046870172\n",
            "Epoch 3201/3500 - Loss: 0.003055392997339368 - Val Loss: 0.000612091738730669\n",
            "Epoch 3301/3500 - Loss: 0.0029288087971508503 - Val Loss: 0.00048809999134391546\n",
            "Epoch 3401/3500 - Loss: 0.0025915310252457857 - Val Loss: 0.001151649747043848\n"
          ]
        }
      ],
      "source": [
        "X_train_tensor = torch.LongTensor(X_train).to(device)\n",
        "y_train_tensor = torch.LongTensor(y_train).to(device)\n",
        "X_val_tensor = torch.LongTensor(X_val).to(device)\n",
        "y_val_tensor = torch.LongTensor(y_val).to(device)\n",
        "\n",
        "# Training loop\n",
        "epochs = 3500\n",
        "for epoch in range(epochs):\n",
        "    net.train()\n",
        "    optimizer.zero_grad()\n",
        "    outputs = net(X_train_tensor).float()\n",
        "    loss = criterion(outputs, y_train_tensor)\n",
        "    loss.backward()\n",
        "    optimizer.step()\n",
        "\n",
        "    # Validation\n",
        "    net.eval()\n",
        "    with torch.no_grad():\n",
        "        val_outputs = net(X_val_tensor).float()\n",
        "        val_loss = criterion(val_outputs, y_val_tensor)\n",
        "\n",
        "    if epoch%100 == 0:\n",
        "      print(f\"Epoch {epoch+1}/{epochs} - Loss: {loss.item()} - Val Loss: {val_loss.item()}\")"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def predict(net, number):\n",
        "    net.eval()\n",
        "    with torch.no_grad():\n",
        "        input_tensor = torch.LongTensor([number_to_digits(number)]).to(device)\n",
        "        output = net(input_tensor).float()\n",
        "        return torch.argmax(output).item()"
      ],
      "metadata": {
        "id": "nRTBwpWTnhvT"
      },
      "execution_count": 9,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "test_number = 4587874515\n",
        "print(f\"Actual Iterated Digit Sum: {iterated_digit_sum(test_number)}\")\n",
        "print(f\"Predicted Iterated Digit Sum: {predict(net, test_number)}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "mjtLoiMWrbIO",
        "outputId": "96378ed4-a42a-4ea3-8020-20bdc9c081d9"
      },
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Actual Iterated Digit Sum: 9\n",
            "Predicted Iterated Digit Sum: 6\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "test_number = 15415451\n",
        "print(f\"Actual Iterated Digit Sum: {iterated_digit_sum(test_number)}\")\n",
        "print(f\"Predicted Iterated Digit Sum: {predict(net, test_number)}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "k53MEkrarbKw",
        "outputId": "fdaa59ad-4761-460a-90fb-2721a8c2289f"
      },
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Actual Iterated Digit Sum: 8\n",
            "Predicted Iterated Digit Sum: 8\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "test_number = 52451235\n",
        "print(f\"Actual Iterated Digit Sum: {iterated_digit_sum(test_number)}\")\n",
        "print(f\"Predicted Iterated Digit Sum: {predict(net, test_number)}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "kBRChJdGrbNx",
        "outputId": "bbabbe33-8add-4490-b807-6e7ae1299b42"
      },
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Actual Iterated Digit Sum: 9\n",
            "Predicted Iterated Digit Sum: 9\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "test_number = 852963254\n",
        "print(f\"Actual Iterated Digit Sum: {iterated_digit_sum(test_number)}\")\n",
        "print(f\"Predicted Iterated Digit Sum: {predict(net, test_number)}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "A4zM-ZSZrbQv",
        "outputId": "dc01159c-cd2d-450e-bae7-bccef4c792e1"
      },
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Actual Iterated Digit Sum: 8\n",
            "Predicted Iterated Digit Sum: 8\n"
          ]
        }
      ]
    }
  ]
}