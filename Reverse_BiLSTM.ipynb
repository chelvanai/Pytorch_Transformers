{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "machine_shape": "hm",
      "gpuType": "V100"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 24,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "8aCh5AKY8_Y3",
        "outputId": "b7138667-6601-4c90-ac2b-a64a96abc086"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/3500 - Loss: 2.3004753589630127 - Val Loss: 2.297133684158325\n",
            "Epoch 101/3500 - Loss: 1.1983234882354736 - Val Loss: 1.197767734527588\n",
            "Epoch 201/3500 - Loss: 0.7542758584022522 - Val Loss: 0.7582878470420837\n",
            "Epoch 301/3500 - Loss: 0.49173837900161743 - Val Loss: 0.49660712480545044\n",
            "Epoch 401/3500 - Loss: 0.3008958399295807 - Val Loss: 0.3053213655948639\n",
            "Epoch 501/3500 - Loss: 0.1747964471578598 - Val Loss: 0.17900510132312775\n",
            "Epoch 601/3500 - Loss: 0.10232695192098618 - Val Loss: 0.10600744932889938\n",
            "Epoch 701/3500 - Loss: 0.06253274530172348 - Val Loss: 0.06578018516302109\n",
            "Epoch 801/3500 - Loss: 0.04036607965826988 - Val Loss: 0.04315260052680969\n",
            "Epoch 901/3500 - Loss: 0.027600860223174095 - Val Loss: 0.02992376685142517\n",
            "Epoch 1001/3500 - Loss: 0.019788024947047234 - Val Loss: 0.021717557683587074\n",
            "Epoch 1101/3500 - Loss: 0.014762870967388153 - Val Loss: 0.016375942155718803\n",
            "Epoch 1201/3500 - Loss: 0.01138725969940424 - Val Loss: 0.012749485671520233\n",
            "Epoch 1301/3500 - Loss: 0.009027736261487007 - Val Loss: 0.0101905083283782\n",
            "Epoch 1401/3500 - Loss: 0.0073177022859454155 - Val Loss: 0.008319439366459846\n",
            "Epoch 1501/3500 - Loss: 0.006038202904164791 - Val Loss: 0.006908520590513945\n",
            "Epoch 1601/3500 - Loss: 0.0050584254786372185 - Val Loss: 0.005820555612444878\n",
            "Epoch 1701/3500 - Loss: 0.004295211751013994 - Val Loss: 0.00496795866638422\n",
            "Epoch 1801/3500 - Loss: 0.0036875831428915262 - Val Loss: 0.004285793285816908\n",
            "Epoch 1901/3500 - Loss: 0.003195599652826786 - Val Loss: 0.003730922006070614\n",
            "Epoch 2001/3500 - Loss: 0.00279153510928154 - Val Loss: 0.0032732952386140823\n",
            "Epoch 2101/3500 - Loss: 0.0024554706178605556 - Val Loss: 0.0028912308625876904\n",
            "Epoch 2201/3500 - Loss: 0.002172865206375718 - Val Loss: 0.0025687802117317915\n",
            "Epoch 2301/3500 - Loss: 0.0019332803785800934 - Val Loss: 0.002294321544468403\n",
            "Epoch 2401/3500 - Loss: 0.001728797098621726 - Val Loss: 0.002059118589386344\n",
            "Epoch 2501/3500 - Loss: 0.0015528606018051505 - Val Loss: 0.0018560432363301516\n",
            "Epoch 2601/3500 - Loss: 0.001400332315824926 - Val Loss: 0.0016794338589534163\n",
            "Epoch 2701/3500 - Loss: 0.00126723013818264 - Val Loss: 0.001524853752925992\n",
            "Epoch 2801/3500 - Loss: 0.001150407362729311 - Val Loss: 0.001388785196468234\n",
            "Epoch 2901/3500 - Loss: 0.0010473360307514668 - Val Loss: 0.0012683914974331856\n",
            "Epoch 3001/3500 - Loss: 0.000955967407207936 - Val Loss: 0.0011613719398155808\n",
            "Epoch 3101/3500 - Loss: 0.0008746227249503136 - Val Loss: 0.001065832213498652\n",
            "Epoch 3201/3500 - Loss: 0.0008019175729714334 - Val Loss: 0.0009802145650610328\n",
            "Epoch 3301/3500 - Loss: 0.0007367059588432312 - Val Loss: 0.0009032223606482148\n",
            "Epoch 3401/3500 - Loss: 0.0006780358380638063 - Val Loss: 0.0008337747422046959\n"
          ]
        }
      ],
      "source": [
        "import numpy as np\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.optim as optim\n",
        "\n",
        "def number_to_digits(n):\n",
        "    return [int(d) for d in str(n)]\n",
        "\n",
        "num_samples = 20000\n",
        "# For debugging, limit the maximum number to 100\n",
        "X_numbers = np.random.randint(0, 100_000, size=num_samples)\n",
        "\n",
        "X = [number_to_digits(x) for x in X_numbers]\n",
        "y = [number_to_digits(int(str(x)[::-1])) for x in X_numbers]\n",
        "\n",
        "max_len = max(max(len(x) for x in X), max(len(x) for x in y))\n",
        "\n",
        "for x in X:\n",
        "    while len(x) < max_len:\n",
        "        x.insert(0, 0)\n",
        "\n",
        "for x in y:\n",
        "    while len(x) < max_len:\n",
        "        x.insert(0, 0)\n",
        "\n",
        "X = np.array(X)\n",
        "y = np.array(y)\n",
        "\n",
        "split = int(0.8 * num_samples)\n",
        "X_train, X_val = X[:split], X[split:]\n",
        "y_train, y_val = y[:split], y[split:]\n",
        "\n",
        "class BiLSTMSeq2Seq(nn.Module):\n",
        "    def __init__(self, input_dim, hidden_dim, output_dim, num_layers):\n",
        "        super(BiLSTMSeq2Seq, self).__init__()\n",
        "\n",
        "        self.embedding = nn.Embedding(input_dim, hidden_dim)\n",
        "        self.lstm = nn.LSTM(hidden_dim, hidden_dim, num_layers, batch_first=True, bidirectional=True)\n",
        "        self.fc = nn.Linear(hidden_dim * 2, output_dim)\n",
        "\n",
        "    def forward(self, x):\n",
        "        x = self.embedding(x)\n",
        "        lstm_out, _ = self.lstm(x)\n",
        "        output = self.fc(lstm_out)\n",
        "        return output\n",
        "\n",
        "input_dim = 10\n",
        "hidden_dim = 64\n",
        "output_dim = 10\n",
        "num_layers = 2\n",
        "\n",
        "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
        "\n",
        "net = BiLSTMSeq2Seq(input_dim, hidden_dim, output_dim, num_layers).to(device)\n",
        "\n",
        "criterion = nn.CrossEntropyLoss()\n",
        "optimizer = optim.Adam(net.parameters(), lr=0.0005)\n",
        "\n",
        "X_train_tensor = torch.LongTensor(X_train).to(device)\n",
        "y_train_tensor = torch.LongTensor(y_train).to(device)\n",
        "X_val_tensor = torch.LongTensor(X_val).to(device)\n",
        "y_val_tensor = torch.LongTensor(y_val).to(device)\n",
        "\n",
        "epochs = 3500\n",
        "for epoch in range(epochs):\n",
        "    net.train()\n",
        "    optimizer.zero_grad()\n",
        "    outputs = net(X_train_tensor)\n",
        "\n",
        "    outputs_reshaped = outputs.view(-1, 10)\n",
        "    y_train_reshaped = y_train_tensor.view(-1)\n",
        "\n",
        "    loss = criterion(outputs_reshaped, y_train_reshaped)\n",
        "    loss.backward()\n",
        "    optimizer.step()\n",
        "\n",
        "    net.eval()\n",
        "    with torch.no_grad():\n",
        "        val_outputs = net(X_val_tensor)\n",
        "        val_outputs_reshaped = val_outputs.view(-1, 10)\n",
        "        y_val_reshaped = y_val_tensor.view(-1)\n",
        "        val_loss = criterion(val_outputs_reshaped, y_val_reshaped)\n",
        "\n",
        "    if epoch % 100 == 0:\n",
        "        print(f\"Epoch {epoch + 1}/{epochs} - Loss: {loss.item()} - Val Loss: {val_loss.item()}\")\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def reverse_number_prediction(model, number):\n",
        "    # Convert the number to its digit sequence\n",
        "    digits = number_to_digits(number)\n",
        "\n",
        "    # Pad the sequence to max_len\n",
        "    while len(digits) < max_len:\n",
        "        digits.insert(0, 0)\n",
        "\n",
        "    # Convert to tensor and move to the device\n",
        "    tensor_input = torch.LongTensor([digits]).to(device)\n",
        "\n",
        "    # Get the prediction\n",
        "    model.eval()\n",
        "    with torch.no_grad():\n",
        "        outputs = model(tensor_input)\n",
        "        _, predicted = torch.max(outputs, 2)  # Argmax over the last dimension to get predicted digit\n",
        "\n",
        "    reversed_digits = predicted[0].cpu().numpy().tolist()\n",
        "\n",
        "    # Convert digit sequence back to a number\n",
        "    reversed_number = int(''.join(map(str, reversed_digits)))\n",
        "\n",
        "    return reversed_number\n",
        "\n"
      ],
      "metadata": {
        "id": "H8TM1aW59Bmj"
      },
      "execution_count": 25,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Test the function\n",
        "given_number = 123887\n",
        "predicted_reversed = reverse_number_prediction(net, given_number)\n",
        "print(f\"Given Number: {given_number}\")\n",
        "print(f\"Predicted Reversed Number: {predicted_reversed}\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "B9heJNNh9Bsl",
        "outputId": "c981b5ec-e0bd-46ac-e051-1fb1480da57d"
      },
      "execution_count": 30,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Given Number: 123887\n",
            "Predicted Reversed Number: 783211\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "V2M-K3N39BvW"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "7b3FGTeP9ByJ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "MBEpg5Ov9B02"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "2DU3zCz59B3o"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "yu7HrqOA9B61"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "d2JZnwQk9B-l"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "byfQ4z2b9CCI"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "SpytdGmH9CFI"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "7wfVAyt69CI1"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "DqPCD2h09CPW"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}